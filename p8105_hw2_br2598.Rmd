---
title: "Homework 2 P8105, Brandon Rojas"
output: github_document
---

```{r}
library(tidyverse)
library(readxl)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## **Problem 1** 
Read and clean the Mr. Trash Wheel sheet:

* specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in read_excel 
* use reasonable variable names -- 
* omit rows that do not include dumpster-specific data -- 
* round the number of sports balls to the nearest integer  -- 


* Write a paragraph about these data; you are encouraged to use inline R. Be sure to **note the number of observations in both resulting datasets**, and give examples of **key variables**. For available data, **what was the total precipitation in 2018**? What was the **median number of sports balls in a dumpster in 2019**?

```{r}
mr_trash_data = read_excel("./data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx", sheet = "Mr. Trash Wheel") #Header image on row 1 removed automatically?

mr_trash_data = janitor::clean_names(mr_trash_data) #snake case col names
mr_trash_data = select(mr_trash_data, -'x15', -'x16', -'x17') #Removes the comments and several unused empty columns
mr_trash_data = mr_trash_data[!is.na(mr_trash_data$dumpster), ] #Removes the "Totals" rows.
mr_trash_data$`sports_balls` <-round(mr_trash_data$`sports_balls`) 


```

## Problem 1, Precipitation data

* Read and clean precipitation data for 2018 and 2019. 
* For each, omit rows without precipitation data and add a variable for year. 
* Next, combine precipitation datasets *use join* 
* convert month to a character variable (the variable month.name is built into R and should be useful).  

```{r}
prcp_19 = read_excel("./data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx", sheet = "2019 Precipitation", skip = 1)
prcp_19 = prcp_19[!is.na(prcp_19$Month), ] #Removes the "Totals" rows.
prcp_19['Year'] <- 2019


prcp_18 = read_excel("./data/Trash-Wheel-Collection-Totals-7-2020-2.xlsx", sheet = "2018 Precipitation", skip = 1)
prcp_18 = prcp_18[!is.na(prcp_18$Month), ] #Removes the "Totals" rows.
prcp_18['Year'] <- 2018


prcp_2yrs <- bind_rows(prcp_18, prcp_19) %>% mutate(Month = month.abb[as.numeric(Month)])

```


## **Problem 2**

**Our goal is to merge these into a single data frame using year and month as keys across datasets.**

* First, clean the data in pols-month.csv. Use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name; 

* create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable. 

```{r}
pols_month = read_csv("./data/pols-month.csv") %>%
  separate(mon, sep = "-", into = c("year", "month", "day")) %>% 
  mutate(month = month.abb[as.numeric(month)]) %>%
  mutate(president = recode(prez_gop, `1` = "gop", `0` = "dem"), president = factor(president)) %>% 
  select(-prez_dem, -prez_gop, -day) %>%
  mutate(month = str_to_lower(month)) %>%
  mutate(year = as.numeric(year))

```

* Second, clean the data in snp.csv using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns.  


If year is from 00 to 15, add 2000

else

add 1900


```{r}
snp_close = read_csv("./data/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, sep = "/", into = c("month", "day", "year")) %>% 
  relocate(year, month) %>% 
  mutate(month = month.abb[as.numeric(month)]) %>% 
  select(-day) %>% 
  mutate(month = str_to_lower(month)) %>%
  mutate(year = as.numeric(year)) #%>%
#  mutate(year = ifelse(year <= 15, year + 2000, year))

#Not sure about year values (lacking first two digits?) Class for year is "character", but was "date" for prez data. Converted to numeric.

```

* Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values. 

```{r}
unemployment = read_csv("./data/unemployment.csv") %>%
  janitor::clean_names() %>%
  pivot_longer(jan:dec, 
               names_to = "month",
               values_to ="rate_unemployment")

#This made me go back and convert to lower cased abbreviations instead of using month.name as I could not find a way to convert from abb --> full name. 

```


* Join the datasets by **merging snp into pols**, and merging unemployment into the result.  

```{r}
merge_snp_pols <- left_join(pols_month, snp_close, by = c("month" = "month", "year" = "year")) # SNP closing data is gone due to the 2 digit year error.

merge_unemployment_with_snp_pol <- left_join(merge_snp_pols, unemployment, by = c("month" = "month", "year" = "year")) 
```

* Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset.


These three datasets contain unemployment rates, the closing value of the SNP index, and the current assembly of government.Each dataset contained months and years, which were used to link the three sheets together. The resulting dataset could, in theory be used to examine correlations, perhaps tenuously, between government, employment, and the SNP points at market close.


* give the dimension
```{r}
dim(merge_unemployment_with_snp_pol)
```
* range of years
```{r}
range(merge_unemployment_with_snp_pol$year)
```

* names of key variables.
```{r}
head(merge_unemployment_with_snp_pol)
```

## **Problem 3** 
* Load and tidy the data.

* Note that, although these data may seem fairly well formatted initially, the names of a categorical predictor and the case structure of string variables changed over time; you’ll need to address this in your data cleaning.  

* Also, some rows seem duplicated, and these will need to be removed (hint: google something like “dplyr remove duplicate rows” to get started).  

* Produce a well-structured, reader-friendly table showing the rank in popularity of the name “Olivia” as a female baby name over time; this should have rows for ethnicities and columns for year.  

* Produce a similar table showing the most popular name among male children over time.  

* Finally, for male, white non-hispanic children born in 2016, produce a scatter plot showing the number of children with a name (y axis) against the rank in popularity of that name (x axis).  


```{r}
nyc_names = read_csv("./data/Popular_Baby_Names.csv") %>%
  janitor::clean_names() %>%
  mutate(childs_first_name = str_to_lower(childs_first_name)) %>%
  distinct()
  

```


